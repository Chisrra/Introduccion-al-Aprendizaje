{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_general(MC: confusion_matrix, nombres: numpy.ndarray):\n",
    "    \"\"\"Calculo de la precisión global y por categoria, y el error global de la matriz de confusión\n",
    "\n",
    "    Args:\n",
    "        MC (confusion_matrix): Matriz de confussion se muestran los aciertos y desaciertos de la prediccion por clasificación\n",
    "        nombres (ndarray, optional): El array que contiene las diferentes clasificaciones. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuples(tuples): Retorna una tupla de tuplas, donde cada una de estas contiene una descripcion de los datos calculados y dichos datos\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy_global = numpy.sum(MC.diagonal()) / numpy.sum(MC)\n",
    "    err_global = 1 - accuracy_global\n",
    "    accuracy_category = pandas.DataFrame(MC.diagonal()/numpy.sum(MC, axis=1)).T\n",
    "\n",
    "    if not nombres.size:\n",
    "        accuracy_category.colums = nombres\n",
    "    \n",
    "    return ((\"Matriz de confusión: \",MC), (\"Precision Global: \", accuracy_global), (\"Error Global\", err_global), (\"Precisión por categoría\", accuracy_category))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     s.largo  s.ancho  p.largo  p.ancho\n",
      "0        5.1      3.5      1.4      0.2\n",
      "1        4.9      3.0      1.4      0.2\n",
      "2        4.7      3.2      1.3      0.2\n",
      "3        4.6      3.1      1.5      0.2\n",
      "4        5.0      3.6      1.4      0.2\n",
      "..       ...      ...      ...      ...\n",
      "145      6.7      3.0      5.2      2.3\n",
      "146      6.3      2.5      5.0      1.9\n",
      "147      6.5      3.0      5.2      2.0\n",
      "148      6.2      3.4      5.4      2.3\n",
      "149      5.9      3.0      5.1      1.8\n",
      "\n",
      "[150 rows x 4 columns]           tipo\n",
      "0       setosa\n",
      "1       setosa\n",
      "2       setosa\n",
      "3       setosa\n",
      "4       setosa\n",
      "..         ...\n",
      "145  virginica\n",
      "146  virginica\n",
      "147  virginica\n",
      "148  virginica\n",
      "149  virginica\n",
      "\n",
      "[150 rows x 1 columns]\n",
      "----------------\n",
      "La predicciones del Testing son: ['virginica' 'versicolor' 'setosa' 'virginica' 'setosa' 'virginica'\n",
      " 'setosa' 'versicolor' 'versicolor' 'versicolor' 'virginica' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'versicolor'\n",
      " 'setosa' 'setosa' 'virginica' 'versicolor' 'setosa' 'setosa' 'virginica'\n",
      " 'setosa' 'setosa' 'versicolor' 'versicolor' 'setosa' 'virginica'\n",
      " 'versicolor' 'setosa' 'virginica' 'virginica' 'versicolor' 'setosa'\n",
      " 'virginica' 'versicolor' 'versicolor' 'virginica' 'setosa' 'virginica'\n",
      " 'setosa' 'setosa']\n",
      "----------------------------\n",
      "Matriz de confusión: \n",
      "[[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n",
      "Precision Global: \n",
      "0.9777777777777777\n",
      "Error Global\n",
      "0.022222222222222254\n",
      "Precisión por categoría\n",
      "     0         1    2\n",
      "0  1.0  0.944444  1.0\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filename = \"iris.csv\"    \n",
    "    datos = pandas.read_csv(filename, delimiter=\";\", decimal=\".\")\n",
    "   \n",
    "    # x es la variable predictoria\n",
    "    # y es la variable a predecir\n",
    "    x = datos.iloc[:,:4]\n",
    "    y = datos.iloc[:,4:5]\n",
    "    print(x,y, end=\"\\n----------------\\n\")\n",
    "\n",
    "    x_tarin, x_test, y_train, y_test = train_test_split(x,y, train_size=0.7, random_state=0)\n",
    "    # print(x_tarin, x_test, y_train, y_test, sep=\"\\n+++++++++++++\\n\")\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=1000)\n",
    "\n",
    "    mlp.fit(x_tarin, y_train.iloc[:,0])\n",
    "    \n",
    "    accuracy = mlp.score(x_test, y_test.iloc[:,0])\n",
    "\n",
    "    print(\"La predicciones del Testing son: {}\".format(mlp.predict(x_test)), end=\"\\n----------------------------\\n\")\n",
    "\n",
    "    MC = confusion_matrix(y_test, mlp.predict(x_test)) \n",
    "\n",
    "    resultados = indices_general(MC, numpy.unique(y))\n",
    "\n",
    "    for i in resultados:\n",
    "        print(f\"{i[0]}\\n{i[1]}\")\n",
    "\n",
    "    print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "718715b73e0a150c6aa0738ed8aa0727f84182aa4188b2f31734b0cdc51341ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
